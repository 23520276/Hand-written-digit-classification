{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d93a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu sang ImageFolder t·∫°i D:\\\\code_things\\\\do an cuoi ki mon may hoc\\\\hand_Written(CNN)\\\\resnet_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\reald\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\reald\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\reald/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:02<00:00, 21.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Loss: 122.1108\n",
      "[Epoch 2] Loss: 27.1797\n",
      "[Epoch 3] Loss: 12.0833\n",
      "[Epoch 4] Loss: 10.2606\n",
      "[Epoch 5] Loss: 7.3587\n",
      "[Epoch 6] Loss: 6.1355\n",
      "[Epoch 7] Loss: 6.1116\n",
      "[Epoch 8] Loss: 7.4025\n",
      "[Epoch 9] Loss: 11.3274\n",
      "[Epoch 10] Loss: 12.0810\n",
      "üéØ Accuracy: 94.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9998/9998 [12:06<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o resnet_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# =======================\n",
    "# 1. CHU·∫®N H√ìA D·ªÆ LI·ªÜU\n",
    "# =======================\n",
    "def prepare_imagefolder_structure(src_dir, dst_dir):\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    for i in range(10):\n",
    "        os.makedirs(os.path.join(dst_dir, str(i)), exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(src_dir):\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            try:\n",
    "                label = file.split('_')[0]\n",
    "                label_folder = os.path.join(dst_dir, label)\n",
    "                if os.path.isdir(label_folder):\n",
    "                    shutil.copy(\n",
    "                        os.path.join(src_dir, file),\n",
    "                        os.path.join(label_folder, file)\n",
    "                    )\n",
    "            except:\n",
    "                continue\n",
    "    print(f\" ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu sang ImageFolder t·∫°i {dst_dir}\")\n",
    "\n",
    "# =======================\n",
    "# 2. H√ÄM TRAIN RESNET18\n",
    "# =======================\n",
    "def train_resnet18(data_dir, num_epochs=10, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # ƒê√°nh gi√°\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"üéØ Accuracy: {correct / total * 100:.2f}%\")\n",
    "    return model\n",
    "\n",
    "# =======================\n",
    "# 3. D·ª∞ ƒêO√ÅN ·∫¢NH M·ªöI\n",
    "# =======================\n",
    "def predict_on_folder(model, input_dir, output_csv=\"resnet_predictions.csv\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    results = []\n",
    "    for file in tqdm(os.listdir(input_dir)):\n",
    "        if file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            img_path = os.path.join(input_dir, file)\n",
    "            from PIL import Image\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = transform(img).unsqueeze(0).to(device)\n",
    "                output = model(img)\n",
    "                _, pred = torch.max(output, 1)\n",
    "                results.append([file, pred.item()])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(results, columns=[\"filename\", \"predicted_digit\"])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {output_csv}\")\n",
    "\n",
    "# =======================\n",
    "# 4. MAIN PIPELINE\n",
    "# =======================\n",
    "def main():\n",
    "    merged_data = r\"D:\\\\code_things\\\\do an cuoi ki mon may hoc\\\\hand_Written(CNN)\\\\merged_data\"\n",
    "    resnet_data = r\"D:\\\\code_things\\\\do an cuoi ki mon may hoc\\\\hand_Written(CNN)\\\\resnet_data\"\n",
    "    unlabeled_dir = r\"D:\\\\code_things\\\\do an cuoi ki mon may hoc\\\\hand_Written(CNN)\\\\data no label\\\\data.2025\"\n",
    "\n",
    "    prepare_imagefolder_structure(merged_data, resnet_data)\n",
    "    model = train_resnet18(resnet_data)\n",
    "    predict_on_folder(model, unlabeled_dir)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
